{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "# import tifffile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_h5(directory, experiment_title):\n",
    "    \"\"\"\n",
    "    Import H5 files, extract image data and metadata, and perform denoising.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "        Path to the directory containing the H5 files.\n",
    "    experiment_title : str\n",
    "        Title of the experiment, used to identify relevant files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing image arrays, exposure times, darkcount images, and denoised images.\n",
    "    \"\"\"\n",
    "    laser_wavelengths = {'1': '670', '2': '760', '3': '808'}\n",
    "    emission_filters = {'12': 'BP1150', '13': 'BP1200', '14': 'BP1250', '15': 'BP1300', '16': 'BP1350', '17': 'BP1575'}\n",
    "\n",
    "    # Input validation\n",
    "    if not os.path.isdir(directory):\n",
    "        raise ValueError(f\"The directory {directory} does not exist.\")\n",
    "    if not isinstance(experiment_title, str):\n",
    "        raise ValueError(\"experiment_title must be a string.\")\n",
    "\n",
    "    # Get the list of darkcount files\n",
    "    darkcount_files = sorted([f for f in os.listdir(directory) if f.startswith('darkcounts')],\n",
    "                             key=lambda x: float(x[10:-3]))\n",
    "\n",
    "    # Initialize a dictionary to store the image file lists\n",
    "    image_files = {}\n",
    "\n",
    "    # Get the list of image files for each parameter combination\n",
    "    for laser_key, laser_value in laser_wavelengths.items():\n",
    "        for filter_key, filter_value in emission_filters.items():\n",
    "            key = f\"{experiment_title}_{laser_value}_{filter_value}\"\n",
    "            image_files[key] = sorted([f for f in os.listdir(directory) if f.startswith(f\"{experiment_title}_{laser_key}_{filter_key}\")],\n",
    "                                      key=lambda x: float(x.split('_')[-1][:-3]))\n",
    "\n",
    "    # Read the darkcount files and store the data\n",
    "    darkcount_data = []\n",
    "    exposure_times = []\n",
    "    for file in darkcount_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        with h5py.File(file_path, 'r') as h5f:\n",
    "            darkcount = h5f['Cube']['Images'][()]\n",
    "            exposure_time = h5f['Cube']['TimeExposure'][()].item()\n",
    "            darkcount_data.append(darkcount)\n",
    "            exposure_times.append(exposure_time)\n",
    "\n",
    "    # Concatenate the darkcount data into an array with dimensions (num_exposure_times, height, width)\n",
    "    darkcount_array = np.squeeze(np.array(darkcount_data))\n",
    "\n",
    "    # Convert exposure_times to a NumPy array\n",
    "    exposure_times = np.array(exposure_times)\n",
    "\n",
    "    # Read the image files and store the data for each parameter combination\n",
    "    image_arrays = {}\n",
    "    for key, files in image_files.items():\n",
    "        image_data = []\n",
    "        for file in files:\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with h5py.File(file_path, 'r') as h5f:\n",
    "                image = h5f['Cube']['Images'][()]\n",
    "                image_data.append(image)\n",
    "        image_arrays[key] = np.squeeze(np.array(image_data))\n",
    "\n",
    "    # Calculate the mean and standard deviation of pixel intensities for each exposure time in the darkcount cube\n",
    "    darkcount_mean = np.mean(darkcount_array, axis=(1, 2))\n",
    "    darkcount_std = np.std(darkcount_array, axis=(1, 2))\n",
    "    print(\"Average darkcount value:\", darkcount_mean)\n",
    "    print(\"Darkcount standard deviation:\", darkcount_std)\n",
    "\n",
    "    # Define the threshold multiplier (e.g., 2 for mean + 2*std)\n",
    "    threshold_multiplier = 0\n",
    "\n",
    "    # Create a dictionary to store the denoised image arrays\n",
    "    image_denoised_arrays = {}\n",
    "\n",
    "    # Zero out pixels below the threshold in each image cube\n",
    "    for key in image_arrays.keys():\n",
    "        threshold = darkcount_mean + threshold_multiplier * darkcount_std\n",
    "        denoised_array = np.where(image_arrays[key] > threshold[:, np.newaxis, np.newaxis],\n",
    "                                  image_arrays[key] - threshold[:, np.newaxis, np.newaxis],\n",
    "                                  0)\n",
    "        # Convert to 16-bit integers\n",
    "        image_denoised_arrays[key] = denoised_array.astype(np.uint16)\n",
    "\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print(\"Denoised arrays shape:\", image_denoised_arrays[key].shape)\n",
    "\n",
    "    # Print the shapes of the arrays\n",
    "    print(\"Darkcount array shape:\", darkcount_array.shape)\n",
    "    print(\"Exposure times array shape:\", exposure_times.shape)\n",
    "    print(\"Exposure times:\", exposure_times)\n",
    "    for key in image_arrays.keys():\n",
    "        print(f\"Image array shape for {key}:\", image_arrays[key].shape)\n",
    "\n",
    "    return {\n",
    "        \"images\": image_arrays,\n",
    "        \"exposure_times\": exposure_times,\n",
    "        \"darkcount_images\": darkcount_array,\n",
    "        \"denoised_images\": image_denoised_arrays\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_array(image_set, exposure_times):\n",
    "    \"\"\"\n",
    "    Plot a tight arrangement of the full series of exposure times for each imaging condition on the same intensity scale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_set : dict\n",
    "        A dictionary containing image arrays for different conditions.\n",
    "    exposure_times : numpy.ndarray\n",
    "        An array of exposure times corresponding to the images.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(image_set, dict):\n",
    "        raise ValueError(\"image_set must be a dictionary.\")\n",
    "    if not isinstance(exposure_times, np.ndarray):\n",
    "        raise ValueError(\"exposure_times must be a numpy array.\")\n",
    "\n",
    "    # Extract the minimum and maximum intensity values for each image array\n",
    "    min_max_dict = {key: (np.min(array), np.max(array)) for key, array in image_set.items()}\n",
    "\n",
    "    # Print the minimum and maximum intensity values for each image array\n",
    "    for key, (min_val, max_val) in min_max_dict.items():\n",
    "        print(f\"Intensity range for {key}: Min = {min_val}, Max = {max_val}\")\n",
    "\n",
    "    # Plot the image arrays using the same intensity scale\n",
    "    for key, array in image_set.items():\n",
    "        fig, axes = plt.subplots(1, array.shape[0], figsize=(15, 2))\n",
    "        fig.suptitle(key)\n",
    "    \n",
    "        min_val, max_val = min_max_dict[key]\n",
    "    \n",
    "        for i in range(array.shape[0]):\n",
    "            ax = axes[i]\n",
    "            ax.imshow(array[i, :, :], cmap='gray', vmin=min_val, vmax=max_val)\n",
    "            ax.set_title(f'{exposure_times[i]} s')\n",
    "            ax.axis('off')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# data = import_h5('/path/to/directory', 'experiment_name')\n",
    "# plot_image_array(data['denoised_images'], data['exposure_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearWeight(pixel_value, z_min, z_max):\n",
    "    \"\"\"\n",
    "    Linear weighting function based on pixel intensity that reduces the\n",
    "    weight of pixel values that are near saturation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pixel_value : int or numpy.ndarray\n",
    "        A pixel intensity value or array of values\n",
    "    z_min : int\n",
    "        Minimum possible pixel value\n",
    "    z_max : int\n",
    "        Maximum possible pixel value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    weight : float or numpy.ndarray\n",
    "        The weight(s) corresponding to the input pixel intensity(ies)\n",
    "    \"\"\"\n",
    "    pixel_value = np.asarray(pixel_value)\n",
    "    mid = (z_min + z_max) / 2\n",
    "    weight = np.where(pixel_value <= mid, \n",
    "                      pixel_value - z_min, \n",
    "                      z_max - pixel_value)\n",
    "    return weight.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weighting_function(weighting_function, z_min, z_max):\n",
    "    \"\"\"\n",
    "    Plot the weighting function against pixel intensity.\n",
    "\n",
    "    Parameters:\n",
    "    weighting_function : callable\n",
    "        The weighting function to be plotted\n",
    "    z_min : int\n",
    "        Minimum pixel value\n",
    "    z_max : int\n",
    "        Maximum pixel value\n",
    "    \"\"\"\n",
    "    pixel_values = np.arange(z_min, z_max + 1)\n",
    "    weights = [weighting_function(z, z_min, z_max) for z in pixel_values]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(pixel_values, weights)\n",
    "    plt.title(\"Weighting Function\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Weight\")\n",
    "    plt.xlim(z_min, z_max)\n",
    "    plt.ylim(0, max(weights) * 1.1)  # Set y-axis limit to slightly above max weight\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleIntensities(images, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Randomly sample pixel intensities from the exposure stack.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : numpy.ndarray\n",
    "        A 3D array containing a stack of single-channel images\n",
    "        Shape: (num_images, height, width)\n",
    "    num_samples : int, optional\n",
    "        Number of samples to take per image (default is 1000)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    intensity_samples : numpy.array\n",
    "        An array containing sampled intensity values from each\n",
    "        exposure layer (shape = num_samples x num_images)\n",
    "    z_min : int\n",
    "        Minimum intensity value in the images\n",
    "    z_max : int\n",
    "        Maximum intensity value in the images\n",
    "    \"\"\"\n",
    "    if not isinstance(images, np.ndarray) or images.ndim != 3:\n",
    "        raise ValueError(\"images must be a 3D numpy array\")\n",
    "\n",
    "    num_images, height, width = images.shape\n",
    "    z_min, z_max = np.min(images), np.max(images)\n",
    "    print(f\"z_max: {z_max}; z_min: {z_min}\")\n",
    "\n",
    "    # Ensure we sample the full range\n",
    "    intensity_range = np.linspace(z_min, z_max, num_samples, dtype=int)\n",
    "\n",
    "    # Initialize the intensity values array\n",
    "    intensity_samples = np.zeros((num_samples, num_images), dtype=np.uint16)\n",
    "\n",
    "    for i, intensity in enumerate(intensity_range):\n",
    "            for j in range(num_images):\n",
    "                # Find pixels close to this intensity\n",
    "                mask = np.abs(images[j] - intensity) < (z_max - z_min) / num_samples\n",
    "                if np.any(mask):\n",
    "                    idx = np.random.choice(np.where(mask.ravel())[0])\n",
    "                    row, col = np.unravel_index(idx, (height, width))\n",
    "                    intensity_samples[i, j] = images[j, row, col]\n",
    "                else:\n",
    "                    # If no close pixels, take the closest one\n",
    "                    idx = np.argmin(np.abs(images[j] - intensity))\n",
    "                    row, col = np.unravel_index(idx, (height, width))\n",
    "                    intensity_samples[i, j] = images[j, row, col]\n",
    "    \n",
    "    print(intensity_samples)\n",
    "\n",
    "    return intensity_samples, z_min, z_max\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # Calculate the step size for the sliding window\n",
    "    # step = max(1, (z_max - z_min) // num_samples)\n",
    "\n",
    "    # for i in range(num_samples):\n",
    "    #     # Define the intensity range for this sample\n",
    "    #     low = z_min + i * step\n",
    "    #     high = min(low + step, z_max + 1)\n",
    "\n",
    "    #     # Sample from all images\n",
    "    #     for j in range(num_images):\n",
    "    #         # Find pixels within the current intensity range\n",
    "    #         mask = (images[j] >= low) & (images[j] < high)\n",
    "    #         if np.any(mask):\n",
    "    #             # Randomly select one pixel from the valid pixels\n",
    "    #             valid_indices = np.where(mask)\n",
    "    #             idx = np.random.randint(len(valid_indices[0]))\n",
    "    #             row, col = valid_indices[0][idx], valid_indices[1][idx]\n",
    "    #             intensity_samples[i, j] = images[j, row, col]\n",
    "    #         else:\n",
    "    #             # If no pixels in this range, sample randomly from the image\n",
    "    #             row, col = np.random.randint(height), np.random.randint(width)\n",
    "    #             intensity_samples[i, j] = images[j, row, col]\n",
    "\n",
    "    # # Remove any all-zero rows (should be rare)\n",
    "    # intensity_samples = intensity_samples[~np.all(intensity_samples == 0, axis=1)]\n",
    "\n",
    "    # # Check for sufficient sampling\n",
    "    # print(f\"Number of samples: {intensity_samples.shape[0]}\")\n",
    "    # if intensity_samples.shape[0] > (z_max - z_min) / 2:\n",
    "    #     print(\"Sampling satisfied\")\n",
    "    # else:\n",
    "    #     print(\"Warning: Sampling may be insufficient\")\n",
    "\n",
    "    # print(intensity_samples)\n",
    "\n",
    "    # return intensity_samples, z_min, z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeResponseCurve(intensity_samples, exposure_times, z_min, z_max):\n",
    "    # Flatten the samples and corresponding exposure times\n",
    "    intensities = intensity_samples.flatten()\n",
    "    exposures = np.repeat(exposure_times, intensity_samples.shape[0])\n",
    "    \n",
    "    # Remove any zero intensities\n",
    "    non_zero = intensities > 0\n",
    "    intensities = intensities[non_zero]\n",
    "    exposures = exposures[non_zero]\n",
    "    \n",
    "    # Fit a polynomial (you can adjust the degree)\n",
    "    coeffs = np.polyfit(np.log(intensities), np.log(exposures), deg=5)\n",
    "    \n",
    "    # Create the response curve\n",
    "    pixel_values = np.arange(z_min, z_max + 1)\n",
    "    response_curve = np.exp(np.polyval(coeffs, np.log(pixel_values)))\n",
    "    \n",
    "    return response_curve\n",
    "\n",
    "\n",
    "# def computeResponseCurve(intensity_samples, log_exposures, smoothing_lambda, weighting_function, z_min, z_max):\n",
    "#     \"\"\"\n",
    "#     Find the camera response curve for a single color channel\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     intensity_samples : numpy.ndarray\n",
    "#         Sampled intensity values (shape = num_samples x num_images)\n",
    "#     log_exposures : numpy.ndarray\n",
    "#         Log exposure times (size == num_images)\n",
    "#     smoothing_lambda : float\n",
    "#         Constant for scale correction between data and smoothing terms\n",
    "#     weighting_function : callable\n",
    "#         Function that computes a weight from a pixel intensity\n",
    "#     z_min : int\n",
    "#         Minimum intensity value\n",
    "#     z_max : int\n",
    "#         Maximum intensity value\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     numpy.ndarray\n",
    "#         Vector g(z) where g[i] is the log exposure of intensity value z_min + i\n",
    "#     \"\"\"\n",
    "#     if not isinstance(intensity_samples, np.ndarray) or intensity_samples.ndim != 2:\n",
    "#         raise ValueError(\"intensity_samples must be a 2D numpy array\")\n",
    "#     if not isinstance(log_exposures, np.ndarray) or log_exposures.ndim != 1:\n",
    "#         raise ValueError(\"log_exposures must be a 1D numpy array\")\n",
    "#     if intensity_samples.shape[1] != log_exposures.shape[0]:\n",
    "#         raise ValueError(\"Number of images in intensity_samples and log_exposures must match\")\n",
    "\n",
    "#     num_samples, num_images = intensity_samples.shape\n",
    "#     intensity_range = z_max - z_min + 1\n",
    "\n",
    "#     # Calculate the number of constraints\n",
    "#     data_constraints = num_samples * num_images\n",
    "#     smoothness_constraints = intensity_range - 2\n",
    "#     monotonicity_constraints = intensity_range - 1\n",
    "#     centering_constraint = 1\n",
    "\n",
    "#     total_constraints = data_constraints + smoothness_constraints + monotonicity_constraints + centering_constraint\n",
    "\n",
    "#     mat_A = np.zeros((total_constraints, intensity_range), dtype=np.float64)\n",
    "#     mat_b = np.zeros((total_constraints, 1), dtype=np.float64)\n",
    "\n",
    "#     k = 0\n",
    "#     # 1. Add data-fitting constraints\n",
    "#     for i in range(num_samples):\n",
    "#         for j in range(num_images):\n",
    "#             z_ij = intensity_samples[i, j]\n",
    "#             w_ij = weighting_function(z_ij, z_min, z_max)\n",
    "#             mat_A[k, z_ij - z_min] = w_ij\n",
    "#             mat_b[k, 0] = w_ij * log_exposures[j]\n",
    "#             k += 1\n",
    "\n",
    "#     # 2. Add smoothness constraints\n",
    "#     for z_k in range(z_min + 1, z_max):\n",
    "#         w_k = weighting_function(z_k, z_min, z_max)\n",
    "#         mat_A[k, z_k - z_min - 1:z_k - z_min + 2] = w_k * smoothing_lambda * np.array([-1, 2, -1])\n",
    "#         k += 1\n",
    "\n",
    "#     # 3. Add monotonicity constraints\n",
    "#     for z_k in range(z_min, z_max):\n",
    "#         if k < total_constraints - 1:  # Ensure we don't exceed matrix dimensions\n",
    "#             mat_A[k, z_k - z_min:z_k - z_min + 2] = np.array([-1, 1])\n",
    "#             k += 1\n",
    "\n",
    "#     # 4. Add constraint to fix the curve at the middle\n",
    "#     mat_A[k, (z_max - z_min) // 2] = 1\n",
    "#     mat_b[k, 0] = 0\n",
    "\n",
    "#     # Solve the system\n",
    "#     x = np.linalg.lstsq(mat_A, mat_b, rcond=None)[0]\n",
    "\n",
    "#     return x.flatten()    \n",
    "    \n",
    "#     # num_samples, num_images = intensity_samples.shape\n",
    "#     # intensity_range = z_max - z_min\n",
    "\n",
    "#     # mat_A = np.zeros((num_images * num_samples + intensity_range, num_samples + intensity_range + 1), dtype=np.float64)\n",
    "#     # mat_b = np.zeros((mat_A.shape[0], 1), dtype=np.float64)\n",
    "\n",
    "#     # # 1. Add data-fitting constraints\n",
    "#     # k = 0\n",
    "#     # for i in range(num_samples):\n",
    "#     #     for j in range(num_images):\n",
    "#     #         z_ij = intensity_samples[i, j]\n",
    "#     #         w_ij = weighting_function(z_ij, z_min, z_max)\n",
    "#     #         mat_A[k, z_ij - z_min] = w_ij\n",
    "#     #         mat_A[k, (intensity_range + 1) + i] = -w_ij\n",
    "#     #         mat_b[k, 0] = w_ij * log_exposures[j]\n",
    "#     #         k += 1\n",
    "\n",
    "#     # # 2. Add smoothing constraints\n",
    "#     # for z_k in range(z_min + 1, z_max):\n",
    "#     #     w_k = weighting_function(z_k, z_min, z_max)\n",
    "#     #     mat_A[k, z_k - z_min - 1:z_k - z_min + 2] = w_k * smoothing_lambda * np.array([-1, 2, -1])\n",
    "#     #     k += 1\n",
    "\n",
    "#     # # Add monotonicity constraint\n",
    "#     #     for z_k in range(z_min, z_max):\n",
    "#     #         mat_A[k, z_k - z_min:z_k - z_min + 2] = np.array([-1, 1])\n",
    "#     #         k += 1\n",
    "\n",
    "\n",
    "#     # # 3. Add color curve centering constraint\n",
    "#     # mat_A[k, (z_max - z_min) // 2] = 1\n",
    "\n",
    "#     # inv_A = np.linalg.pinv(mat_A)\n",
    "#     # x = np.dot(inv_A, mat_b)\n",
    "\n",
    "#     # g = x[0: intensity_range + 1]\n",
    "#     # return g[:, 0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRadianceMap(images, log_exposure_times, response_curve, weighting_function, z_min, z_max):\n",
    "    \"\"\"\n",
    "    Calculate a radiance map for each pixel from the response curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : numpy.ndarray\n",
    "        3D array containing single-channel images (num_images, height, width)\n",
    "    log_exposure_times : numpy.ndarray\n",
    "        Array containing the log exposure times for each image\n",
    "    response_curve : numpy.ndarray\n",
    "        Least-squares fitted log exposure of each pixel value z\n",
    "    weighting_function : callable\n",
    "        Function that computes the weights\n",
    "    z_min : int\n",
    "        Minimum intensity value\n",
    "    z_max : int\n",
    "        Maximum intensity value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The image radiance map (in log space)\n",
    "    \"\"\"\n",
    "    if not isinstance(images, np.ndarray) or images.ndim != 3:\n",
    "        raise ValueError(\"images must be a 3D numpy array\")\n",
    "    if not isinstance(log_exposure_times, np.ndarray) or log_exposure_times.ndim != 1:\n",
    "        raise ValueError(\"log_exposure_times must be a 1D numpy array\")\n",
    "    if images.shape[0] != log_exposure_times.shape[0]:\n",
    "        raise ValueError(\"Number of images and exposure times must match\")\n",
    "\n",
    "    num_images, height, width = images.shape\n",
    "    img_rad_map = np.zeros((height, width), dtype=np.float32)\n",
    "    sum_weights = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        w = weighting_function(images[i], z_min, z_max)\n",
    "        img_rad_map += w * (response_curve[np.clip(images[i] - z_min, 0, len(response_curve) - 1)] - log_exposure_times[i])\n",
    "        sum_weights += w\n",
    "\n",
    "    # Avoid division by zero\n",
    "    sum_weights[sum_weights == 0] = 1e-6\n",
    "    img_rad_map /= sum_weights\n",
    "\n",
    "    return img_rad_map\n",
    "    \n",
    "    \n",
    "    \n",
    "    # num_images, height, width = images.shape\n",
    "    # img_rad_map = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    # for i in range(height):\n",
    "    #     for j in range(width):\n",
    "    #         g = np.array([response_curve[int(images[k, i, j]) - z_min] for k in range(num_images)])\n",
    "    #         w = np.array([weighting_function(images[k, i, j], z_min, z_max) for k in range(num_images)])\n",
    "    #         sum_w = np.sum(w)\n",
    "    #         if sum_w > 0:\n",
    "    #             img_rad_map[i, j] = np.sum(w * (g - log_exposure_times)) / sum_w\n",
    "    #         else:\n",
    "    #             img_rad_map[i, j] = g[num_images // 2] - log_exposure_times[num_images // 2]\n",
    "\n",
    "    # return img_rad_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalToneMapping(image, gamma):\n",
    "    \"\"\"\n",
    "    Global tone mapping using gamma correction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        Image needed to be corrected\n",
    "    gamma : float\n",
    "        The number for gamma correction. Higher value for brighter result; lower for darker\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The resulting image after gamma correction\n",
    "    \"\"\"\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"image must be a numpy array\")\n",
    "    if not isinstance(gamma, (int, float)) or gamma <= 0:\n",
    "        raise ValueError(\"gamma must be a positive number\")\n",
    "\n",
    "    # Ensure all values are non-negative\n",
    "    image = np.maximum(image, 0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    max_val = np.max(image)\n",
    "    if max_val == 0:\n",
    "        return np.zeros_like(image)\n",
    "    \n",
    "    return cv2.pow(image / max_val, 1.0 / gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensityAdjustment(image, template):\n",
    "    \"\"\"\n",
    "    Tune image intensity based on template\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        2D array of image to be adjusted\n",
    "    template : numpy.ndarray\n",
    "        2D array of template image (typically middle image from stack)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The resulting image after intensity adjustment\n",
    "    \"\"\"\n",
    "    if not isinstance(image, np.ndarray) or image.ndim != 2:\n",
    "        raise ValueError(\"image must be a 2D numpy array\")\n",
    "    if not isinstance(template, np.ndarray) or template.ndim != 2:\n",
    "        raise ValueError(\"template must be a 2D numpy array\")\n",
    "    if image.shape != template.shape:\n",
    "        raise ValueError(\"image and template must have the same shape\")\n",
    "\n",
    "    image_avg = np.average(image)\n",
    "    template_avg = np.average(template)\n",
    "    return image * (template_avg / image_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeHDR(images, exposure_times, smoothing_lambda=1000., gamma=0.6):\n",
    "    \"\"\"\n",
    "    Computational pipeline to produce the HDR images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : numpy.ndarray\n",
    "        A 3D array containing an exposure stack of single-channel images\n",
    "        Shape: (num_images, height, width)\n",
    "    log_exposure_times : numpy.ndarray\n",
    "        The log exposure times for each image in the exposure stack\n",
    "    smoothing_lambda : float, optional\n",
    "        A constant value to correct for scale differences between\n",
    "        data and smoothing terms in the constraint matrix\n",
    "    gamma : float, optional\n",
    "        Gamma value for tone mapping\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (hdr_image, response_curve)\n",
    "        hdr_image : numpy.ndarray\n",
    "            The resulting HDR image with intensities scaled to fit uint8 range\n",
    "        response_curve : numpy.ndarray\n",
    "            The computed camera response function\n",
    "    \"\"\"\n",
    "    if not isinstance(images, np.ndarray) or images.ndim != 3:\n",
    "        raise ValueError(\"images must be a 3D numpy array\")\n",
    "    if not np.issubdtype(images.dtype, np.integer):\n",
    "        raise ValueError(\"images must be an integer type\")\n",
    "    if not isinstance(log_exposure_times, np.ndarray) or log_exposure_times.ndim != 1:\n",
    "        raise ValueError(\"log_exposure_times must be a 1D numpy array\")\n",
    "    if images.shape[0] != log_exposure_times.shape[0]:\n",
    "        raise ValueError(\"Number of images and exposure times must match\")\n",
    "\n",
    "    print(images.dtype)\n",
    "    # Sample image intensities\n",
    "    intensity_samples, z_min, z_max = sampleIntensities(images, num_samples=5000)\n",
    "\n",
    "    # Compute Response Curve\n",
    "    response_curve = computeResponseCurve(intensity_samples, log_exposure_times, smoothing_lambda, linearWeight, z_min, z_max)\n",
    "\n",
    "    # Plot the response curve\n",
    "    plot_response_curve(intensity_samples, log_exposure_times, response_curve, z_min, z_max)\n",
    "\n",
    "    # Apply Savitzky-Golay filter to smooth the response curve\n",
    "    from scipy.signal import savgol_filter\n",
    "    response_curve = savgol_filter(response_curve, window_length=51, polyorder=3)\n",
    "\n",
    "    # Build radiance map\n",
    "    img_rad_map = computeRadianceMap(images, log_exposure_times, response_curve, linearWeight, z_min, z_max)\n",
    "\n",
    "    print(f\"1. Radiance map (log space) min: {np.min(img_rad_map)}, max: {np.max(img_rad_map)}\")\n",
    "    plot_radiance_map(img_rad_map)\n",
    "\n",
    "    # Convert to linear space\n",
    "    img_rad_map = np.exp(img_rad_map)\n",
    "    print(f\"2. Radiance map (linear space) min: {np.min(img_rad_map)}, max: {np.max(img_rad_map)}\")\n",
    "    plot_radiance_map(img_rad_map)\n",
    "\n",
    "    # Normalize the radiance map to [0, 1] range\n",
    "    img_rad_map = (img_rad_map - np.min(img_rad_map)) / (np.max(img_rad_map) - np.min(img_rad_map))\n",
    "    print(f\"3. Normalized radiance map min: {np.min(img_rad_map)}, max: {np.max(img_rad_map)}\")\n",
    "    plot_radiance_map(img_rad_map)\n",
    "\n",
    "    # Global tone mapping \n",
    "    def adaptive_log_tone_mapping(x, a=0.5):\n",
    "        return (np.log(1 + a * x) / np.log(1 + a)) / (np.log(1 + a * np.max(x)) / np.log(1 + a))\n",
    "\n",
    "    image_mapped = adaptive_log_tone_mapping(img_rad_map)\n",
    "    print(f\"4. After tone mapping min: {np.min(image_mapped)}, max: {np.max(image_mapped)}\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image_mapped, cmap='gray')\n",
    "    plt.title('After Tone Mapping')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Adjust image intensity based on the middle image from image stack\n",
    "    template = images[len(images) // 2]\n",
    "    scale_factor = np.mean(template) / np.mean(image_mapped)\n",
    "    image_tuned = image_mapped * scale_factor\n",
    "    print(f\"5. After intensity adjustment min: {np.min(image_tuned)}, max: {np.max(image_tuned)}\")\n",
    "\n",
    "    # Normalize to [0, 1] range again after adjustment\n",
    "    image_tuned = (image_tuned - np.min(image_tuned)) / (np.max(image_tuned) - np.min(image_tuned))\n",
    "\n",
    "    # Apply contrast stretching\n",
    "    p2, p98 = np.percentile(image_tuned, (2, 98))\n",
    "    image_tuned = exposure.rescale_intensity(image_tuned, in_range=(p2, p98))\n",
    "\n",
    "    # Convert to 8-bit image\n",
    "    hdr_image = (image_tuned * 255).astype(np.uint8)\n",
    "    print(f\"6. Final HDR image min: {np.min(hdr_image)}, max: {np.max(hdr_image)}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(hdr_image, cmap='gray')\n",
    "    plt.title('Final HDR Image')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    return hdr_image, response_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_response_curve(intensity_samples, exposure_times, response_curve, z_min, z_max):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot individual data points\n",
    "    for j in range(intensity_samples.shape[1]):\n",
    "        plt.scatter(intensity_samples[:, j], exposure_times[j], alpha=0.1, s=1, c='blue')\n",
    "    \n",
    "    # Plot the fitted response curve\n",
    "    pixel_values = np.arange(z_min, z_max + 1)\n",
    "    plt.plot(pixel_values, response_curve, 'r-', linewidth=2, label='Fitted Response Curve')\n",
    "    \n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Exposure Time')\n",
    "    plt.title('Camera Response Function')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# def plot_response_curve(response_curve, z_min, z_max):\n",
    "#     \"\"\"\n",
    "#     Plot the Camera Response Function (CRF)\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     response_curve : numpy.ndarray\n",
    "#         The computed camera response function\n",
    "#     z_min : int\n",
    "#         Minimum intensity value\n",
    "#     z_max : int\n",
    "#         Maximum intensity value\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(range(z_min, z_max + 1), response_curve)\n",
    "#     plt.title(\"Camera Response Function\")\n",
    "#     plt.xlabel(\"Pixel Value\")\n",
    "#     plt.ylabel(\"Log Exposure\")\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "def plot_radiance_map(img_rad_map):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rad_map, cmap='viridis')\n",
    "    plt.colorbar(label='Radiance')\n",
    "    plt.title('Radiance Map')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# def plot_response_curve(intensity_samples, log_exposures, response_curve, z_min, z_max):\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "    \n",
    "#     # Plot individual data points\n",
    "#     for j in range(intensity_samples.shape[1]):\n",
    "#         plt.scatter(intensity_samples[:, j], log_exposures[j] - response_curve[intensity_samples[:, j] - z_min],\n",
    "#                     alpha=0.1, s=1, c='blue')\n",
    "    \n",
    "#     # Plot the fitted response curve\n",
    "#     pixel_values = np.arange(z_min, z_max + 1)\n",
    "#     plt.plot(pixel_values, response_curve, 'r-', linewidth=2, label='Fitted Response Curve')\n",
    "    \n",
    "#     plt.xlabel('Pixel Value')\n",
    "#     plt.ylabel('Log Exposure')\n",
    "#     plt.title('Camera Response Function')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Plot residuals\n",
    "#     plt.figure(figsize=(12, 4))\n",
    "#     for j in range(intensity_samples.shape[1]):\n",
    "#         residuals = log_exposures[j] - response_curve[intensity_samples[:, j] - z_min]\n",
    "#         plt.scatter(intensity_samples[:, j], residuals, alpha=0.1, s=1, c='blue')\n",
    "#     plt.axhline(y=0, color='r', linestyle='-')\n",
    "#     plt.xlabel('Pixel Value')\n",
    "#     plt.ylabel('Residuals')\n",
    "#     plt.title('CRF Residuals')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average darkcount value: [ 799.21032715  964.28184509 1061.37977295 1094.0200592  1105.97271118\n",
      " 1123.6138031  1137.19124756 1152.92250977 1169.57583618 1184.83742676\n",
      " 1205.35088806 1236.3617218  1280.04559631 1353.41764221 1498.27137451]\n",
      "Darkcount standard deviation: [12.86297416 13.12020853 13.37192913 13.52632673 13.71151908 13.73150302\n",
      " 13.7205852  13.56561546 13.3067028  13.20703569 13.33763676 13.98644368\n",
      " 15.13072328 16.61922603 18.79814508]\n",
      "Threshold: [ 799.21032715  964.28184509 1061.37977295 1094.0200592  1105.97271118\n",
      " 1123.6138031  1137.19124756 1152.92250977 1169.57583618 1184.83742676\n",
      " 1205.35088806 1236.3617218  1280.04559631 1353.41764221 1498.27137451]\n",
      "Denoised arrays shape: (15, 640, 512)\n",
      "Darkcount array shape: (15, 640, 512)\n",
      "Exposure times array shape: (15,)\n",
      "Exposure times: [1.0000e-04 2.0000e-04 4.0000e-04 8.0000e-04 1.6000e-03 3.2000e-03\n",
      " 6.4000e-03 1.2800e-02 2.5600e-02 5.1200e-02 1.0240e-01 2.0480e-01\n",
      " 4.0960e-01 8.1920e-01 1.6384e+00]\n",
      "Image array shape for Water_immersed_670_BP1150: (15, 640, 512)\n",
      "Image array shape for Water_immersed_670_BP1200: (15, 640, 512)\n",
      "Image array shape for Water_immersed_670_BP1250: (15, 640, 512)\n",
      "Image array shape for Water_immersed_670_BP1300: (15, 640, 512)\n",
      "Image array shape for Water_immersed_670_BP1350: (15, 640, 512)\n",
      "Image array shape for Water_immersed_670_BP1575: (15, 640, 512)\n",
      "Image array shape for Water_immersed_760_BP1150: (15, 640, 512)\n",
      "Image array shape for Water_immersed_760_BP1200: (15, 640, 512)\n",
      "Image array shape for Water_immersed_760_BP1250: (15, 640, 512)\n",
      "Image array shape for Water_immersed_760_BP1300: (15, 640, 512)\n",
      "Image array shape for Water_immersed_760_BP1350: (15, 640, 512)\n",
      "Image array shape for Water_immersed_760_BP1575: (15, 640, 512)\n",
      "Image array shape for Water_immersed_808_BP1150: (15, 640, 512)\n",
      "Image array shape for Water_immersed_808_BP1200: (15, 640, 512)\n",
      "Image array shape for Water_immersed_808_BP1250: (15, 640, 512)\n",
      "Image array shape for Water_immersed_808_BP1300: (15, 640, 512)\n",
      "Image array shape for Water_immersed_808_BP1350: (15, 640, 512)\n",
      "Image array shape for Water_immersed_808_BP1575: (15, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "# Import and process the H5 files\n",
    "directory = '/Users/allisondennis/Library/CloudStorage/OneDrive-NortheasternUniversity/AMD/IR VIVO data/240329_Water_immersed'\n",
    "experiment_title = 'Water_immersed'\n",
    "\n",
    "data = import_h5(directory,experiment_title)\n",
    "\n",
    "# Plot the denoised images\n",
    "# plot_image_array(data['denoised_images'], data['exposure_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0    0    5 ...    0   19   12]\n",
      "  [   0   16    0 ...    3   18    0]\n",
      "  [   1    0    2 ...    4   25    2]\n",
      "  ...\n",
      "  [   4   19    0 ...    0    0    1]\n",
      "  [  27   20   12 ...    0    0    0]\n",
      "  [  34   46   26 ...    0    0    0]]\n",
      "\n",
      " [[   0    0   17 ...    6   15   34]\n",
      "  [   8    0    2 ...    0    0    3]\n",
      "  [   4    0    9 ...    7   10    4]\n",
      "  ...\n",
      "  [   0    0    9 ...    2    0    0]\n",
      "  [  20   10    0 ...   11    0    2]\n",
      "  [  33   37    8 ...   26    0    0]]\n",
      "\n",
      " [[  10    1   21 ...   11   25    0]\n",
      "  [   4    0    0 ...    0    0    5]\n",
      "  [   0    0   20 ...    0    0    0]\n",
      "  ...\n",
      "  [   0    0    5 ...    0    0    0]\n",
      "  [  35    7    0 ...    0    0    0]\n",
      "  [  25   34    0 ...   36    0   16]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 262  236  296 ...   81   68   68]\n",
      "  [ 248  233  217 ...   77  108   62]\n",
      "  [ 240  246  283 ...  104   81   81]\n",
      "  ...\n",
      "  [   0    3   29 ...   25    2   20]\n",
      "  [   0   46   24 ...   25   36   15]\n",
      "  [  13    0   12 ...    0   19   17]]\n",
      "\n",
      " [[ 507  495  542 ...  186  165  172]\n",
      "  [ 487  506  537 ...  185  210  174]\n",
      "  [ 464  513  471 ...  175  174  188]\n",
      "  ...\n",
      "  [  36   38   32 ...   67   44   25]\n",
      "  [   7   21   11 ...    7   44   42]\n",
      "  [  15   18   49 ...   55   38   16]]\n",
      "\n",
      " [[1005 1003 1040 ...  320  342  289]\n",
      "  [ 955  987  978 ...  384  363  318]\n",
      "  [ 951 1005 1081 ...  338  352  345]\n",
      "  ...\n",
      "  [  29   30   57 ...   73   97   78]\n",
      "  [  38   80   71 ...   66   43   73]\n",
      "  [  53   39   49 ...   69   77   66]]]\n",
      "uint16\n",
      "z_max: 3904; z_min: 0\n",
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   1    1    1 ...    1    1    1]\n",
      " ...\n",
      " [   0    0    0 ... 3904 3904    0]\n",
      " [   0    0    0 ... 3904 3904    0]\n",
      " [   0    0    0 ... 3904 3904    0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "computeResponseCurve() takes 4 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(images)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Compute HDR image and get response curve\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m hdr_image, response_curve \u001b[38;5;241m=\u001b[39m \u001b[43mcomputeHDR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexposure_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Plot the weighting function and response curve\u001b[39;00m\n\u001b[1;32m     13\u001b[0m z_min, z_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(images), np\u001b[38;5;241m.\u001b[39mmax(images)\n",
      "Cell \u001b[0;32mIn[39], line 41\u001b[0m, in \u001b[0;36mcomputeHDR\u001b[0;34m(images, exposure_times, smoothing_lambda, gamma)\u001b[0m\n\u001b[1;32m     38\u001b[0m intensity_samples, z_min, z_max \u001b[38;5;241m=\u001b[39m sampleIntensities(images, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Compute Response Curve\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m response_curve \u001b[38;5;241m=\u001b[39m \u001b[43mcomputeResponseCurve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintensity_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_exposure_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinearWeight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Plot the response curve\u001b[39;00m\n\u001b[1;32m     44\u001b[0m plot_response_curve(intensity_samples, log_exposure_times, response_curve, z_min, z_max)\n",
      "\u001b[0;31mTypeError\u001b[0m: computeResponseCurve() takes 4 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "# Choose a specific image set for HDR processing\n",
    "key = 'Water_immersed_670_BP1150'  # Or any other key from your data\n",
    "images = data['denoised_images'][key]\n",
    "log_exposure_times = np.log(data['exposure_times'])\n",
    "exposure_times = (data['exposure_times'])\n",
    "\n",
    "print(images)\n",
    "\n",
    "# Compute HDR image and get response curve\n",
    "hdr_image, response_curve = computeHDR(images, exposure_times)\n",
    "\n",
    "# Plot the weighting function and response curve\n",
    "z_min, z_max = np.min(images), np.max(images)\n",
    "plot_weighting_function(linearWeight, z_min, z_max)\n",
    "plot_response_curve(response_curve, z_min, z_max)\n",
    "\n",
    "# Display the HDR image\n",
    "plt.figure()\n",
    "plt.imshow(hdr_image, cmap='gray')\n",
    "plt.title(\"HDR Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [31  0  0 ...  0  0  0]\n",
      " [19 44  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(hdr_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QDimages_240604",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
