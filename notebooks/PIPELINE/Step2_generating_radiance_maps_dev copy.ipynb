{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the h5_import code to import the experimental data from the IR VIVO and save npy files containing the darkcount-subtracted pixel intensities (i.e., denoised images) and their respective exposure times.\n",
    "\n",
    "Next use these images to generate radiance maps and HDR images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Water_immersed_808_BP1300\n",
      "Images shape: (15, 640, 512)\n",
      "Exposure times shape: (15,)\n",
      "Slinear shape: (640, 512)\n",
      "Sd shape: (640, 512)\n",
      "bias shape: (640, 512)\n",
      "Zmax_precomputed shape: (15, 640, 512)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m loaded_data \u001b[38;5;241m=\u001b[39m load_clipped_denoised_data(directory, experiment_title)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Process HDR images and get all necessary data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_hdr_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save CRF data for future analysis\u001b[39;00m\n\u001b[1;32m     20\u001b[0m crf_file \u001b[38;5;241m=\u001b[39m save_crf_data(processed_data, directory, experiment_title)\n",
      "File \u001b[0;32m~/Spectral_demixing/notebooks/PIPELINE/Step2_image_radiance_dev.py:309\u001b[0m, in \u001b[0;36mprocess_hdr_images\u001b[0;34m(directory, experiment_title, base_data_folder, smoothing_lambda)\u001b[0m\n\u001b[1;32m    306\u001b[0m Zmax_precomputed \u001b[38;5;241m=\u001b[39m precompute_zmax(Slinear, Sd, bias, exposure_times)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZmax_precomputed shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mZmax_precomputed\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m radiance_map, response_curve, z_min, z_max, intensity_samples, log_exposures \u001b[38;5;241m=\u001b[39m \u001b[43mcomputeRadianceMap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexposure_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZmax_precomputed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmoothing_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m radiance_map_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_radiance_map.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(final_data_folder, radiance_map_filename), radiance_map)\n",
      "File \u001b[0;32m~/Spectral_demixing/notebooks/PIPELINE/Step2_image_radiance_dev.py:130\u001b[0m, in \u001b[0;36mcomputeRadianceMap\u001b[0;34m(images, exposure_times, Zmax_precomputed, smoothing_lambda, return_all)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate an unscaled radiance map for each pixel from the response curve.\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting computeRadianceMap function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 130\u001b[0m intensity_samples, log_exposures, z_min, z_max \u001b[38;5;241m=\u001b[39m \u001b[43msampleIntensities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexposure_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZmax_precomputed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished sampleIntensities function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m response_curve \u001b[38;5;241m=\u001b[39m computeResponseCurve(intensity_samples, log_exposures, exposure_times, smoothing_lambda, adaptive_weight, z_min, z_max, Zmax_precomputed)\n",
      "File \u001b[0;32m~/Spectral_demixing/notebooks/PIPELINE/Step2_image_radiance_dev.py:198\u001b[0m, in \u001b[0;36msampleIntensities\u001b[0;34m(images, exposure_times, Zmax_precomputed, num_samples)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    197\u001b[0m     bin_mask \u001b[38;5;241m=\u001b[39m (img \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m bins[j]) \u001b[38;5;241m&\u001b[39m (img \u001b[38;5;241m<\u001b[39m bins[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 198\u001b[0m     pixels_in_bin \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pixels_in_bin[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    200\u001b[0m         num_to_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pixels_in_bin[\u001b[38;5;241m0\u001b[39m]), num_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (num_images \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    " # process_and_save.py\n",
    "\n",
    "from Step2_image_radiance_dev import load_clipped_denoised_data, process_hdr_images, save_crf_data\n",
    "\n",
    "# Your existing setup code here\n",
    "directory = './data/240329_Water_immersed'\n",
    "experiment_title = 'Water_immersed'\n",
    "\n",
    "# Load the processed data\n",
    "loaded_data = load_clipped_denoised_data(directory, experiment_title)\n",
    "\n",
    "# Process HDR images and get all necessary data\n",
    "processed_data = process_hdr_images(directory, experiment_title, smoothing_lambda=1000)\n",
    "\n",
    "# Save CRF data for future analysis\n",
    "crf_file = save_crf_data(processed_data, directory, experiment_title)\n",
    "\n",
    "print(f\"CRF data saved to: {crf_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CRF data from: ./data/240329_Water_immersed/final_data/Water_immersed_crf_data.npz\n",
      "Keys in the loaded file:\n",
      "  key_0\n",
      "  radiance_map_0\n",
      "  response_curve_0\n",
      "  z_min_0\n",
      "  z_max_0\n",
      "  intensity_samples_0\n",
      "  log_exposures_0\n",
      "  key_1\n",
      "  radiance_map_1\n",
      "  response_curve_1\n",
      "  z_min_1\n",
      "  z_max_1\n",
      "  intensity_samples_1\n",
      "  log_exposures_1\n",
      "  key_2\n",
      "  radiance_map_2\n",
      "  response_curve_2\n",
      "  z_min_2\n",
      "  z_max_2\n",
      "  intensity_samples_2\n",
      "  log_exposures_2\n",
      "  key_3\n",
      "  radiance_map_3\n",
      "  response_curve_3\n",
      "  z_min_3\n",
      "  z_max_3\n",
      "  intensity_samples_3\n",
      "  log_exposures_3\n",
      "  key_4\n",
      "  radiance_map_4\n",
      "  response_curve_4\n",
      "  z_min_4\n",
      "  z_max_4\n",
      "  intensity_samples_4\n",
      "  log_exposures_4\n",
      "  key_5\n",
      "  radiance_map_5\n",
      "  response_curve_5\n",
      "  z_min_5\n",
      "  z_max_5\n",
      "  intensity_samples_5\n",
      "  log_exposures_5\n",
      "  key_6\n",
      "  radiance_map_6\n",
      "  response_curve_6\n",
      "  z_min_6\n",
      "  z_max_6\n",
      "  intensity_samples_6\n",
      "  log_exposures_6\n",
      "  key_7\n",
      "  radiance_map_7\n",
      "  response_curve_7\n",
      "  z_min_7\n",
      "  z_max_7\n",
      "  intensity_samples_7\n",
      "  log_exposures_7\n",
      "  key_8\n",
      "  radiance_map_8\n",
      "  response_curve_8\n",
      "  z_min_8\n",
      "  z_max_8\n",
      "  intensity_samples_8\n",
      "  log_exposures_8\n",
      "  key_9\n",
      "  radiance_map_9\n",
      "  response_curve_9\n",
      "  z_min_9\n",
      "  z_max_9\n",
      "  intensity_samples_9\n",
      "  log_exposures_9\n",
      "  key_10\n",
      "  radiance_map_10\n",
      "  response_curve_10\n",
      "  z_min_10\n",
      "  z_max_10\n",
      "  intensity_samples_10\n",
      "  log_exposures_10\n",
      "  key_11\n",
      "  radiance_map_11\n",
      "  response_curve_11\n",
      "  z_min_11\n",
      "  z_max_11\n",
      "  intensity_samples_11\n",
      "  log_exposures_11\n",
      "  key_12\n",
      "  radiance_map_12\n",
      "  response_curve_12\n",
      "  z_min_12\n",
      "  z_max_12\n",
      "  intensity_samples_12\n",
      "  log_exposures_12\n",
      "  key_13\n",
      "  radiance_map_13\n",
      "  response_curve_13\n",
      "  z_min_13\n",
      "  z_max_13\n",
      "  intensity_samples_13\n",
      "  log_exposures_13\n",
      "  key_14\n",
      "  radiance_map_14\n",
      "  response_curve_14\n",
      "  z_min_14\n",
      "  z_max_14\n",
      "  intensity_samples_14\n",
      "  log_exposures_14\n",
      "  key_15\n",
      "  radiance_map_15\n",
      "  response_curve_15\n",
      "  z_min_15\n",
      "  z_max_15\n",
      "  intensity_samples_15\n",
      "  log_exposures_15\n",
      "  key_16\n",
      "  radiance_map_16\n",
      "  response_curve_16\n",
      "  z_min_16\n",
      "  z_max_16\n",
      "  intensity_samples_16\n",
      "  log_exposures_16\n",
      "  key_17\n",
      "  radiance_map_17\n",
      "  response_curve_17\n",
      "  z_min_17\n",
      "  z_max_17\n",
      "  intensity_samples_17\n",
      "  log_exposures_17\n",
      "Loaded 0 processed data items\n",
      "Warning: No data items were loaded. Checking for alternative data structure...\n",
      "Loaded processed data:\n",
      "Report generation complete\n",
      "Report generation complete\n"
     ]
    }
   ],
   "source": [
    "# generate_report.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from Step2_image_radiance_dev import generate_multi_page_report, adaptive_weight\n",
    "\n",
    "def load_crf_data(crf_file):\n",
    "    \"\"\"Load the saved CRF data.\"\"\"\n",
    "    print(f\"Loading CRF data from: {crf_file}\")\n",
    "    loaded_data = np.load(crf_file, allow_pickle=True)\n",
    "    \n",
    "    print(\"Keys in the loaded file:\")\n",
    "    for key in loaded_data.keys():\n",
    "        print(f\"  {key}\")\n",
    "    \n",
    "    processed_data = []\n",
    "    i = 0\n",
    "    while f'filename_{i}' in loaded_data:\n",
    "        data_item = {}\n",
    "        for key in loaded_data.files:\n",
    "            if key.endswith(f'_{i}'):\n",
    "                data_item[key[:-len(f'_{i}')]] = loaded_data[key]\n",
    "        processed_data.append(data_item)\n",
    "        i += 1\n",
    "    \n",
    "    print(f\"Loaded {len(processed_data)} processed data items\")\n",
    "    \n",
    "    if len(processed_data) == 0:\n",
    "        print(\"Warning: No data items were loaded. Checking for alternative data structure...\")\n",
    "        # Check if the data was saved without indexing\n",
    "        if 'intensity_samples' in loaded_data and 'log_exposures' in loaded_data and 'response_curve' in loaded_data:\n",
    "            processed_data = [{\n",
    "                'intensity_samples': loaded_data['intensity_samples'],\n",
    "                'log_exposures': loaded_data['log_exposures'],\n",
    "                'response_curve': loaded_data['response_curve'],\n",
    "                'z_min': loaded_data['z_min'] if 'z_min' in loaded_data else None,\n",
    "                'z_max': loaded_data['z_max'] if 'z_max' in loaded_data else None,\n",
    "                'radiance_map': loaded_data['radiance_map'] if 'radiance_map' in loaded_data else None,\n",
    "            }]\n",
    "            print(\"Loaded 1 data item using alternative structure\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "# Your existing setup code here\n",
    "directory = './data/240329_Water_immersed'\n",
    "experiment_title = 'Water_immersed'\n",
    "\n",
    "# Load the saved CRF data\n",
    "crf_file = os.path.join(directory, \"final_data\", f\"{experiment_title}_crf_data.npz\")\n",
    "processed_data = load_crf_data(crf_file)\n",
    "\n",
    "print(\"Loaded processed data:\")\n",
    "for i, data in enumerate(processed_data):\n",
    "    print(f\"\\nData item {i+1}:\")\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"  {key} shape: {value.shape}\")\n",
    "            if np.issubdtype(value.dtype, np.number):  # Check if the array contains numeric data\n",
    "                if np.isnan(value).any() or np.isinf(value).any():\n",
    "                    print(f\"  Warning: {key} contains NaN or inf values\")\n",
    "                print(f\"  {key} min: {np.min(value)}, max: {np.max(value)}\")\n",
    "            else:\n",
    "                print(f\"  {key} contains non-numeric data\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "# Generate the multi-page report\n",
    "if processed_data:\n",
    "    try:\n",
    "        generate_multi_page_report(processed_data, directory, experiment_title, adaptive_weight)\n",
    "        print(\"Report generation complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"No data to generate report. Please check the CRF data file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QDimages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
